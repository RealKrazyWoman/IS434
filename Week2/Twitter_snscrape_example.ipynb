{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ea7be1",
   "metadata": {},
   "source": [
    "snscrape\n",
    "\n",
    "Ref: https://github.com/JustAnotherArchivist/snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc978c",
   "metadata": {},
   "source": [
    "Scraping a specific Twitter userâ€™s tweets\n",
    "\n",
    "Let's use this handle: @KimKardashian\n",
    "\n",
    "Using the code, we can scrape 100 tweets from Twitter user @KimKardashian.\n",
    "We then pulled the DateTime, tweet id, text, and username attributes from the tweet objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data \n",
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "handle = 'KimKardashian'\n",
    "\n",
    "# declare a username \n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper('from:' + handle).get_items()): \n",
    "    if i > 10: #number of tweets you want to scrape\n",
    "        break\n",
    "        \n",
    "    #declare the attributes to be returned\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above \n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f72838",
   "metadata": {},
   "source": [
    "Scraping tweets from a text search query\n",
    "\n",
    "Using the code below, we are scraping 100 tweets between June 14, 2020, and August 31, 2021,\n",
    "with the keywords 'SSR Bollywood'.\n",
    "\n",
    "I then pulled attributes DateTime, tweet id, text, and username from the tweet objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "\n",
    "# search terms\n",
    "search_terms = 'SSR Bollywood'\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(search_terms + ' since:2021-06-14 until:2021-08-31').get_items()):\n",
    "    if i > 100:\n",
    "        break\n",
    "    #declare the attributes to be returned\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "\n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78faf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c46c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
